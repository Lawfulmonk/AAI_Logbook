{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-3edc6a29a03e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# De waarden in X_train zijn erg verschillend, een neuraal netwerk verwacht waarden rond 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mval_X\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_X\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mmin_max_scaler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMinMaxScaler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mnn_train_X\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmin_max_scaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_X\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "\n",
    "# De waarden in X_train zijn erg verschillend, een neuraal netwerk verwacht waarden rond 0\n",
    "val_X = train_X.values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "nn_train_X = min_max_scaler.fit_transform(val_X)\n",
    "\n",
    "# Keras verwacht een matrix (array van array's) als output:\n",
    "nn_train_y = train_y.values.reshape(-1,1)\n",
    "nn_test_y = test_y.values.reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "nn_train_y = encoder.fit_transform(nn_train_y)\n",
    "nn_test_y = encoder.transform(nn_test_y)\n",
    "\n",
    "print(train_y[:10])\n",
    "\n",
    "nn_test_X = test_X.values\n",
    "nn_test_X = min_max_scaler.fit_transform(nn_test_X)\n",
    "\n",
    "# Om te zorgen dat we de sigmoid activatie kunnen gebruiken moeten we de data reschapen\n",
    "nn_train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "nn_test_y = np.asarray(test_y).astype('float32').reshape((-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# simple nn\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(30, activation = \"relu\", input_shape = (nn_train_X.shape[1], )))\n",
    "nn_model.add(Dense(20, activation = \"relu\"))\n",
    "nn_model.add(Dense(10, activation = \"relu\"))\n",
    "nn_model.add(Dense(1, activation = \"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stronger nn\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(50, activation = \"relu\", input_shape = (nn_train_X.shape[1], )))\n",
    "nn_model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "nn_model.add(Dense(50, activation = \"relu\"))\n",
    "nn_model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "nn_model.add(Dense(50, activation = \"relu\"))\n",
    "nn_model.add(Dense(1, activation = \"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# even stronger nn\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Embedding(10000, 128, input_length=9))\n",
    "nn_model.add(Dropout(0.25))\n",
    "nn_model.add(Conv1D(64,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "nn_model.add(MaxPooling1D(pool_size=4))\n",
    "nn_model.add(LSTM(70))\n",
    "nn_model.add(Dense(1, activation = \"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Different compilers run one to check result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# standard compiler\n",
    "\n",
    "nn_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.summary()\n",
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))\n",
    "# average accuracy of 0.9798 (more epochs leads to ever so slight increase in accuracy (around 20 epochs per 0.0002))\n",
    "# only 10 epochs\n",
    "# simple nn = 0.8659\n",
    "# stronger nn = 0.8401\n",
    "# even stronger nn ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SGD compiler\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "nn_model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.summary()\n",
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))\n",
    "# heeft meer epochs nodig om dezelfde accuracy te krijgen als adam\n",
    "# only 10 epochs and v2.1.4\n",
    "# simple nn = 0.8785\n",
    "# stronger nn = 0.8505\n",
    "# even stronger nn ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rmsprop compiler\n",
    "\n",
    "nn_model.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.summary()\n",
    "\n",
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))\n",
    "# reached same accuracy as adam but in less epochs\n",
    "# only 10 epochs and v2.1.4\n",
    "# simple nn = 0.8758\n",
    "# stronger nn = 0.8374\n",
    "# even stronger nn ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adadelta compiler\n",
    "\n",
    "nn_model.compile(optimizer = \"adadelta\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.summary()\n",
    "\n",
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))\n",
    "# started at higher accuracy but stagnated at 0.9807\n",
    "# only 10 epochs and v2.1.4\n",
    "# simple nn = 0.8900\n",
    "# stronger nn = 0.8443\n",
    "# even stronger nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adagrad compiler\n",
    "\n",
    "nn_model.compile(optimizer = \"adagrad\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "nn_model.summary()\n",
    "\n",
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))\n",
    "# started at higher accuracy but stagnated at 0.9807 aswell\n",
    "# only 10 epochs and v2.1.4\n",
    "# simple nn  = 0.8916\n",
    "# stronger nn = 0.8450\n",
    "# even stronger nn ="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Continue here after selecting a neural net and compiler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = nn_model.fit(nn_train_X, nn_train_y,\n",
    "                       epochs = 10,\n",
    "                       batch_size = 32,\n",
    "                       validation_data = (x_val_set, y_val_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nn_loss, nn_acc = nn_model.evaluate(nn_test_X, nn_test_y)\n",
    "print(nn_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot history\n",
    "plt.plot(history.history['loss'], label='training data')\n",
    "plt.plot(history.history['val_loss'], label='validation data')\n",
    "plt.title('learning curve')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}